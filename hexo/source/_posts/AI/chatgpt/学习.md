---
title: AI学习
tags: 英语
categories:
  - 理论知识
mathjax: true
top: false
hide: true
abbrlink: ba82741a
date: 2025-12-17 16:13:12
---

下面为你制定一个**针对程序员、已有基础、目标是进一步深入 AI 的系统学习计划**。计划分为三个阶段：**基础强化 → 技术进阶 → 项目实践与落地**，侧重你已有的能力（Agent/Dify/Ollama/Prompt Engineering）继续往模型原理、RAG、Agent 架构、工程化、部署、推理加速等方向拓展。

---

# 🚀 总体目标

让你在 3–6 个月内掌握从 **模型原理 → 推理框架 → RAG → Agent → 模型部署与微调 → AI 工程化** 的完整技能体系，达到可独立落地 AI 项目的水平。

---

# 🧩 第一阶段：基础能力强化（2–4 周）

### 🎯 目标

搭建系统知识框架：大模型原理、向量化、RAG 思维方式、Agent 概念。

### 📚 学习内容

#### 1. 大模型与 Transformer 原理

* Attention / Self-attention
* Positional Encoding
* Pre-train → Fine-tune → RLHF → SFT → DPO
* Tokenization & BPE

💡 **重点**：程序员学习这些不是为了造模型，而是为了读懂论文、理解用法。

#### 2. Embeddings + 向量数据库

你现在能用 RAG，但理解其原理能让你做得更好：

* 向量相似度
* 索引（IVF, HNSW）
* 选择不同 embedding 的技巧
* 高质量 chunking

#### 3. Prompt Engineering 进阶（你已有基础）

* 系统提示词结构
* Decomposition（任务分解）
* 使用 ReAct / CoT / ToT
* 构建鲁棒的 function calling schema

---

# 🧩 第二阶段：技术深度进阶（4–8 周）

### 🎯 目标

掌握真实项目会用的核心技术：RAG、Agent 框架、微调、本地推理加速。

---

## 2.1 ⭐ RAG 进阶（你已经会基本的 RAG）

深入到“工程级 RAG”：

### 学习内容

* Multi-vector RAG（分段 + 标题 + summary）
* Hybrid Search（向量 + 关键词）
* Re-ranking（ColBERT / BGE reranker）
* Query Rewriting（LLM 改写查询）
* Retrieval pipeline 调优方法

### 建议实践项目

👉 用本地 Ollama + Dify + 向量库（Milvus/Qdrant）做一个
**“企业文档智能问答系统 v2”（带重写 + 重排 + 多向量）**

---

## 2.2 ⭐ Agent 系统进阶（基于你已会 Dify Agent）

掌握更底层的 Agent 架构：

### 学习内容

* ReAct 代理
* Tool-Calling（OpenAI-style）
* 多智能体（Multi-Agent）
* 规划器（Planner） & 执行器（Executor）
* 如何给 Agent 加记忆 / 推理链 / 验证器

### 实践建议

👉 自己实现一个轻量级的 Agent 框架（不依赖 Dify）

* 使用 Python + LangChain 或直接裸写
* 能调函数、能分步骤推理

---

## 2.3 ⭐ 模型微调（SFT + LoRA）

你现在基于现成模型开发，下一步是让模型“听你的”。

### 学习内容

* LoRA / QLoRA
* SFT 训练流程
* 数据标注规范（Instruction tuning 格式）
* 本地训练环境管理（llama-factory, swift, axolotl）

### 项目

👉 微调一个小模型（3B~8B）

* 例如让模型学会某行业的领域问答
* 或者“代码生成风格定制化模型”

---

## 2.4 ⭐ 本地模型部署与推理加速

你会 Ollama，但可以更深入：

### 学习内容

* GGUF、AWQ、GPTQ、FP8 的区别
* KV cache, Speculative Decoding
* 使用 llama.cpp / vLLM
* 量化策略选择
* TGI / OpenAI-compatible API

项目：
👉 部署一个高性能 API：

* 使用 vLLM 部署 Mistral、Qwen2.5 或 Llama 模型
* 延迟 < 50ms 的对话系统

---

# 🧩 第三阶段：AI 工程化 + 项目落地（4–8 周）

### 🎯 目标

从能“玩”AI → 能真正做产品。

### 学习内容

#### 1. Prompt + RAG + Agent 的工程落地

* 指标体系：Latency、Token usage、Hallucination
* Observability（监控）
* A/B 测试
* 调用链路可观测（BentoML、Langfuse）

#### 2. API 网关 & 推理服务治理

* 并发管理
* 缓存（Prompt cache / Embedding cache）
* 限流
* 多模型路由（fast model + high-quality model）

---

# 🧱 最终产出（建议你做一个综合项目）

在 2–3 个月结束后，你应该能做一个完整作品，比如：

### ⭐ 企业级 AI 助手（可商用）

* 支持聊天、RAG 文档问答
* 有工具调用，如数据库查询、搜索、业务 API
* 自定义领域模型（你微调的）
* 可监控、可扩展
* 可前端集成（Web + Mobile）

你可以用：

* 前端：Next.js + ChatUI
* 后端：FastAPI
* 模型：vLLM / Ollama
* 数据库：Milvus / PostgreSQL
* Agent：自己写或 Dify 集成

---

# 📅 周计划时间表（建议）

| 阶段  | 周数  | 内容                                              |
| ----- | ----- | ------------------------------------------------- |
| 阶段1 | 1–4   | Transformer 原理、Embedding、RAG 基础、提示词进阶 |
| 阶段2 | 5–12  | RAG 进阶、Agent 结构、微调、推理框架              |
| 阶段3 | 13–20 | 工程化实践、做综合项目                            |

---

# 📌 如果你愿意，我可以为你做：

① **按你的时间**（每天 1h / 2h / 自由）定制更细的日计划
② 给你**每个阶段的资源（文档、课程、开源项目、教程）**
③ 帮你设计一个完整的实战项目并陪学
④ 帮你搭建学习路线图的 Notion / Xmind

---

如果你想，我现在就可以为你：
🔥 制定 **更细化的周计划** 还是
🔥 输出一个 **AI 学习路线图（可视化）**？






------------------------------------------------------------------------------------


下面给你一套 **程序员进阶 AI 的细化路线图（含周计划 + 学习资源 + 实战项目）**。
整个计划为 **12 周（3 个月）**，节奏适中，不会太难，但保证你能从“会用 AI 工具”提升到“能构建真实 AI 系统”的能力。

---

# 🎯 总体结构

* **阶段 1（1–4 周）**：AI 基础原理 + RAG 必备知识
* **阶段 2（5–8 周）**：RAG/Agent 进阶 + 微调 + 本地推理体系
* **阶段 3（9–12 周）**：AI 工程化 + 综合项目落地

每周包含：
⭐ 学习内容
📚 资源链接（全部免费或高质量开源）
🛠 实战任务

---

# =========================

# 🟦 **阶段 1（1–4 周）：AI 基础 & RAG 基础强化**

# =========================

---

# **第 1 周：大模型原理夯实（Transformer）**

### ⭐ 学习内容

* Transformer 架构
* Attention
* Tokenization / BPE
* 预训练 → 微调 → RLHF
* 为什么 LLM 能推理（Representation Learning）

### 📚 推荐资源

* Illustrated Transformer（强烈推荐）
* 《The GPT-3 Paper Explained Visually》
* Lilian Weng Blog（OpenAI）– Foundations
* 《Attention Is All You Need》可视化讲解

### 🛠 实战任务

* 写一个 **最小 Attention Demo（Python）**
* 使用 HuggingFace 调一步模型推理（如 Qwen2.5-1.5B）

---

# **第 2 周：Embedding + 向量数据库 + RAG 基础**

### ⭐ 学习内容

* Embedding 的本质
* 相似度计算（cosine / dot）
* 向量库原理（HNSW / IVF）
* RAG（最简单 pipeline）
* Chunking 策略

### 📚 资源

* Qdrant 官方教程
* Milvus Bootcamp
* BGE embedding 官方文档
* OpenAI RAG Cookbook（免费宝藏）

### 🛠 实战任务

* 搭一个 **本地最简 RAG**

  * Embedding：bge-small
  * 向量库：Qdrant
  * 前端：FastAPI Postman 即可
  * LLM：Ollama（Qwen2.5 / Llama3）

---

# **第 3 周：提示词工程（进阶）**

### ⭐ 学习内容

* Prompt 模板结构（System / User / Few-Shot）
* CoT / ReAct
* Prompt 流程编排（拆分任务）
* Function Calling Schema 设计规范
* 如何减少幻觉 & 结构化输出技巧

### 📚 资源

* Anthropic Prompt Guide
* OpenAI Prompt Guide
* 《Prompt Engineering Guide》（最系统）

### 🛠 实战任务

* 使用 CoT & ReAct 改写你上周的 RAG Prompt
* 设计 5 个 function-calling schema
* 实现一个 **结构化问答 API**

---

# **第 4 周：RAG 强化 + Re-ranking 入门**

### ⭐ 学习内容

* 查询重写（Query Rewriting）
* 文本重排（Reranker：BGE / ColBERT）
* 多向量检索（Title + Chunk + Summary）

### 📚 资源

* Cohere Re-Rank Demo
* ColBERT 论文可视化
* Qwen2.5-Reranker 官方教程

### 🛠 实战任务

* 实现一个高质量 RAG Pipeline：

  * Query Rewriting
  * Vector Search
  * Rerank
* 对比普通 RAG 的效果

---

# =========================

# 🟩 **阶段 2（5–8 周）：RAG 进阶 / Agent / 微调 / 推理框架**

# =========================

---

# **第 5 周：Agent 原理（Dify 底层理解）**

### ⭐ 学习内容

* ReAct 推理链
* Planner / Executor 结构
* 工具调用（Function Calling / Tool Router）
* 多智能体（Multi-Agent）结构

### 📚 资源

* ReAct（Google）原论文
* AutoGen 官方教程
* LangGraph 官方文档（最适合理解 Agent Workflow）

### 🛠 实战任务

* 用 Python 写一个 **轻量级 Agent 引擎**：

  * 能按步骤推理
  * 能调用自定义函数
* 不依赖 LangChain/Dify，自己从零写！

---

# **第 6 周：构建多工具 Agent（类 Dify 系统）**

### ⭐ 学习内容

* 工具注册
* 工具选择（LLM Router）
* 反思机制（Self-Check）
* Agent 任务规划（Task Planning）

### 📚 资源

* Microsoft AutoGen
* LangChain Tools
* DSPy（新一代逻辑驱动 Agent 框架）

### 🛠 实战任务

构建一个具备以下能力的 Agent：

* 工具：搜索、计算、数据库查询、RAG
* Agent 具备“规划”和“反思”能力
  ⚡ **产出一个可复用的 Agent SDK**

---

# **第 7 周：模型微调（SFT + LoRA）**

### ⭐ 学习内容

* LoRA / QLoRA 原理
* 指令微调（Instruction Tuning）
* 数据格式：ShareGPT / Alpaca
* 使用 LLaMA-Factory / Axolotl / Swift 训练

### 📚 资源

* LLaMA-Factory（中文资料齐全）
* QLoRA 论文
* HuggingFace PEFT 文档

### 🛠 实战任务

* 针对某个领域做微调：
  “代码助手 / 售后机器人 / 法律问答 / 医疗 FAQ”
* 模型：3B–7B
* 输出一个可用于推理的 LoRA + GGUF

---

# **第 8 周：本地推理优化（vLLM / llama.cpp）**

### ⭐ 学习内容

* KV Cache
* Speculative Decoding
* Paginated Attention
* vLLM 部署高并发 API
* llama.cpp 量化（GGUF）

### 📚 资源

* vLLM 文档（强烈推荐）
* llama.cpp 文档
* OpenAI TGI 架构学习

### 🛠 实战任务

* 用 vLLM 部署 **你的微调模型**
* 压测（Locust / k6）
* 达成：并发 50、token/s > 150 的目标（根据硬件）

---

# =========================

# 🟧 **阶段 3（9–12 周）：AI 工程化 + 综合项目**

# =========================

---

# **第 9 周：AI 系统工程化（MLOps/LLMOps）**

### ⭐ 学习内容

* Prompt 版本管理
* 数据监控（输入/输出/错误）
* Token 成本优化
* 缓存策略（prompt cache / embedding cache）
* Model Routing（路由策略）

### 📚 资源

* Langfuse（日志 + 监控）
* BentoML（部署）
* Weaviate Blog（最佳实践）

### 🛠 实战任务

* 在你的 RAG/Agent 中加入：

  * 日志
  * 监控
  * Prompt 管理
  * A/B 测试

---

# **第 10 周：安全性与鲁棒性**

### ⭐ 学习内容

* 幻觉治理（Self-check + double-pass）
* 越狱防御（防 Prompt Injection）
* 输出验证器（Schema Validation）
* 计划执行失败处理

### 📚 资源

* Prompt Injection Paper
* LLM Evaluation Guide
* Guardrails AI

### 🛠 实战任务

* 给你的 Agent + RAG 加上
  “防越狱、双重验证、fallback”
* 建立你的判断标准（安全/一致性/稳定性）

---

# **第 11–12 周：综合项目（最终成果）**

你将用 2 周打造一个**可商用级别的 AI 助手系统**。

---

# 🔥 **最终综合项目（强烈推荐你做这个）**

## **《企业级 AI 助手平台（自研 Agent + RAG + 微调模型）》**

### 必须包含功能

✔ Chat 对话
✔ 自研 Agent（工具调用 + 规划）
✔ 高级 RAG：重写 + 搜索 + 重排
✔ 自己微调的模型（如 7B）
✔ 本地部署（vLLM）
✔ 全链路监控（Langfuse）
✔ 前端 UI（Next.js / ChatUI）
✔ 文档上传 / 索引
✔ 自定义工具

### 技术堆栈参考

* **后端**：FastAPI / Node.js
* **向量库**：Qdrant / Milvus
* **LLM 推理**：vLLM / Ollama
* **前端**：Next.js + shadcn/ui
* **Agent 框架**：你自己写的 mini-agent
* **监控**：Langfuse / Prometheus

完成后你会拥有：
⚡ 一个企业级 AI 助手
⚡ 一个自研 Agent 引擎
⚡ 一个微调后的模型
⚡ 完整的工程化能力

> 这套项目直接能写进简历，能拿来卖，也能展示你跑通了 AI 全链路。

---

# 📌 如果你愿意，我还可以帮你：

① **把 12 周计划做成 Notion 模板**
② 给你画成 **可视化路线图（流程图）**
③ 给你做一个 **每周打卡任务板（含 checklist）**
④ 根据你每天的可学习时间进一步细化（如每天 1 小时版）

你想让我下一步帮你做哪一个？





